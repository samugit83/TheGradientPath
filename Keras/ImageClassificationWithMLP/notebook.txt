{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6e23a1",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with Keras and TensorFlow: A Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92d7e0",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Welcome! This notebook provides a guide to a Python script that trains a neural network to recognize handwritten digits from the famous MNIST dataset. This is a classic machine learning project, excellent for beginners.\n",
    "The script (`main.py`) performs several key operations:\n",
    "1. Loads the MNIST dataset (70,000 images of handwritten digits 0-9).\n",
    "2. Builds a Multi-Layer Perceptron (MLP) neural network using Keras with TensorFlow.\n",
    "3. Trains the model to classify the digit images.\n",
    "4. Visualizes the training process and model architecture using TensorBoard and Visualkeras.\n",
    "5. Evaluates the model's performance and makes predictions on new images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e6fb2",
   "metadata": {},
   "source": [
    "## ðŸ“º Watch the Tutorial\n",
    "\n",
    "Prefer a video walkthrough? Check out the accompanying tutorial on YouTube:\n",
    "\n",
    "[Image classification with MLP](https://youtu.be/dkZ3sS_zqog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4aab3",
   "metadata": {},
   "source": [
    "## 2. Core Concepts for Beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3db18",
   "metadata": {},
   "source": [
    "### MNIST Dataset\n",
    "The MNIST dataset is a collection of 70,000 grayscale images, each 28x28 pixels, showing a single handwritten digit (0-9). It contains 60,000 images for training and 10,000 for testing. It's a benchmark dataset for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d688bc",
   "metadata": {},
   "source": [
    "### Image Classification\n",
    "This is the primary task. Given an input image (like a handwritten digit), the goal is to assign it a category or label (in this case, the digit it represents, 0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b556b67",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP) vs. Convolutional Neural Networks (CNNs)\n",
    "While **CNNs** are specialized for image data, recognizing patterns like edges and shapes by processing data in its grid-like topology, this script uses a simpler **MLP**.\n",
    "**Why an MLP here?** The MNIST dataset's simplicity (small, centered digits) allows an MLP to perform reasonably well and serve as a good introduction to neural networks. \n",
    "**Key Difference:** An MLP flattens the 2D image (28x28 pixels) into a 1D vector (784 numbers). It then processes this vector through fully connected layers. This flattening means the MLP doesn't inherently preserve spatial relationships between pixels. CNNs, using convolutional layers, explicitly preserve these spatial structures, making them more powerful for complex image tasks. For understanding basics with MNIST, an MLP is a suitable starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add3148",
   "metadata": {},
   "source": [
    "### Key Steps in the Machine Learning Project\n",
    "1.  **Data Loading and Preprocessing:** Getting data ready for the model.\n",
    "2.  **Model Building:** Defining the neural network's architecture.\n",
    "3.  **Model Compilation:** Configuring the learning process (optimizer, loss function, metrics).\n",
    "4.  **Training:** Feeding data to the model so it can learn.\n",
    "5.  **Evaluation:** Checking model performance on unseen data.\n",
    "6.  **Prediction:** Using the trained model on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f04ab",
   "metadata": {},
   "source": [
    "### Visualization Tools: TensorBoard and Visualkeras\n",
    "*   **TensorBoard:** TensorFlow's visualization toolkit for monitoring training metrics (accuracy, loss), visualizing the model graph, and examining weights.\n",
    "*   **Visualkeras:** A Python library for creating clear, layered diagrams of Keras model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561c10b",
   "metadata": {},
   "source": [
    "## 3. Code Deep Dive: `main.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a4faa",
   "metadata": {},
   "source": [
    "### File Structure Overview\n",
    "The entire logic is within `main.py`, defining several functions for different parts of the process and a `main()` function to orchestrate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1496a5a",
   "metadata": {},
   "source": [
    "### The Imports Section\n",
    "These lines bring in all necessary tools and libraries.\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    Flatten,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import visualkeras\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb1484",
   "metadata": {},
   "source": [
    "### Function: `load_and_preprocess_data()`\n",
    "Responsible for getting and preparing the MNIST dataset.\n",
    "```python\n",
    "def load_and_preprocess_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    y_train = to_categorical(y_train, num_classes=10)\n",
    "    y_test = to_categorical(y_test, num_classes=10)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "```\n",
    "*   `mnist.load_data()`: Downloads and loads the MNIST dataset (training and testing images/labels).\n",
    "*   `astype(\"float32\") / 255.0`: Converts pixel values to `float32` and normalizes them to the range [0, 1]. Normalization helps training converge faster and more reliably.\n",
    "*   `to_categorical(...)`: Performs one-hot encoding on labels (e.g., `5` becomes `[0,0,0,0,0,1,0,0,0,0]`). This is needed for `categorical_crossentropy` loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef231c49",
   "metadata": {},
   "source": [
    "### Function: `build_model(input_shape=(28, 28), num_classes=10)`\n",
    "Defines the MLP architecture using Keras Functional API.\n",
    "```python\n",
    "def build_model(input_shape=(28, 28), num_classes=10):\n",
    "    inputs = Input(shape=input_shape, name=\"mnist_input\")\n",
    "    x = Flatten(name=\"flatten\")(inputs)\n",
    "    x = Dense(128, name=\"dense_1\")(x)\n",
    "    x = Activation(\"relu\", name=\"act_1\")(x)\n",
    "    x = BatchNormalization(name=\"bn_1\")(x)\n",
    "    x = Dropout(0.5, name=\"dropout_1\")(x)\n",
    "    x = Dense(64, name=\"dense_2\")(x)\n",
    "    x = Activation(\"relu\", name=\"act_2\")(x)\n",
    "    x = BatchNormalization(name=\"bn_2\")(x)\n",
    "    x = Dropout(0.5, name=\"dropout_2\")(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"mnist_mlp\")\n",
    "```\n",
    "*   **Keras Functional API:** Allows building complex layer graphs.\n",
    "*   `Input(...)`: Defines the input layer (28x28 images for MNIST).\n",
    "*   `Flatten(...)`: Converts 2D image data to 1D for Dense layers.\n",
    "*   **Dense Blocks:** Consist of:\n",
    "    *   `Dense(...)`: Fully connected layer (128 neurons, then 64 neurons).\n",
    "    *   `Activation(\"relu\", ...)`: ReLU activation function (`f(x) = max(0,x)`), helps with vanishing gradients.\n",
    "    *   `BatchNormalization(...)`: Normalizes previous layer's output, stabilizing learning and speeding up training.\n",
    "    *   `Dropout(0.5, ...)`: Regularization technique to prevent overfitting by randomly dropping 50% of neurons during training.\n",
    "*   **Output Layer:** `Dense(num_classes, activation=\"softmax\", ...)`: Final layer with 10 neurons (one for each digit) and `softmax` activation to output a probability distribution across classes.\n",
    "*   `Model(...)`: Creates the Keras model object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fed880",
   "metadata": {},
   "source": [
    "### Function: `predict_and_save_samples(...)`\n",
    "Makes predictions on test samples and saves them as images.\n",
    "```python\n",
    "def predict_and_save_samples(model, x_test, y_test, num_samples=5, output_dir=\"predictions\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    sample_indices = np.random.choice(x_test.shape[0], num_samples, replace=False)\n",
    "    images = x_test[sample_indices]\n",
    "    labels = y_test[sample_indices]\n",
    "    preds = model.predict(images)\n",
    "    pred_classes = np.argmax(preds, axis=1)\n",
    "    true_classes = np.argmax(labels, axis=1)\n",
    "    print(f\"\\n--- Predictions on {num_samples} samples ---\")\n",
    "    for i, img in enumerate(images):\n",
    "        print(f\"Sample {i+1}: Predicted={pred_classes[i]}, True={true_classes[i]}\")\n",
    "        img_plot = img.reshape(28,28) # Reshape flattened image back to 2D for saving\n",
    "        path = os.path.join(output_dir, f\"sample_{i+1}_true_{true_classes[i]}_pred_{pred_classes[i]}.png\")\n",
    "        plt.imsave(path, img_plot, cmap='gray')\n",
    "        print(f\"  Saved image to: {path}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "```\n",
    "*   Creates an `output_dir` if it doesn't exist.\n",
    "*   Randomly selects `num_samples` from `x_test`.\n",
    "*   `model.predict(images)`: Gets predictions (softmax probabilities) from the model.\n",
    "*   `np.argmax(...)`: Converts probabilities and one-hot labels to class indices (predicted and true digits).\n",
    "*   Loops through samples, prints predictions, reshapes images to 28x28, and saves them using `plt.imsave`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0916f",
   "metadata": {},
   "source": [
    "### Function: `main()`\n",
    "Orchestrates the entire machine learning workflow.\n",
    "```python\n",
    "def main():\n",
    "    # Load data\n",
    "    (x_train, y_train), (x_test, y_test) = load_and_preprocess_data()\n",
    "\n",
    "    # Build and compile model\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.summary() # Prints model summary\n",
    "\n",
    "    # Prepare TensorBoard log directory (timestamped)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logdir = os.path.join(\"logs\", \"graphs\", timestamp)\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "    # Generate and save model architecture using Visualkeras\n",
    "    arch_path = os.path.join(logdir, 'model_visualkeras.png')\n",
    "    visualkeras.layered_view(\n",
    "        model,\n",
    "        to_file=arch_path,\n",
    "        legend=True, draw_volume=False, scale_xy=1.5, scale_z=1, spacing=20\n",
    "    )\n",
    "\n",
    "    # Log Visualkeras image to TensorBoard\n",
    "    with tf.summary.create_file_writer(logdir).as_default():\n",
    "        img_data = tf.io.read_file(arch_path)\n",
    "        img_tensor = tf.image.decode_png(img_data, channels=4)\n",
    "        tf.summary.image(\"Model Visualization\", tf.expand_dims(img_tensor, 0), step=0)\n",
    "\n",
    "    # TensorBoard callback setup\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=logdir,\n",
    "        histogram_freq=1,       # Log histograms every epoch\n",
    "        write_graph=True,       # Log model graph\n",
    "        write_images=True,      # Log model weights as images (if applicable)\n",
    "        update_freq='epoch',    # Update scalars every epoch\n",
    "        profile_batch=1         # Enable profiler for batch 1\n",
    "    )\n",
    "    print(f\"TensorBoard logs in: {os.path.abspath(logdir)}\")\n",
    "    print(\"Run: tensorboard --logdir logs\")\n",
    "\n",
    "    # Train model\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=128,         # Number of samples per gradient update\n",
    "        epochs=10,              # Number of times to iterate over the entire training dataset\n",
    "        validation_split=0.1,   # Fraction of training data for validation\n",
    "        callbacks=[tensorboard_cb], # Callback for TensorBoard logging\n",
    "        verbose=2               # Print one line per epoch\n",
    "    )\n",
    "\n",
    "    # Evaluate model on test data\n",
    "    loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"\\nTest accuracy: {acc:.4f}, loss: {loss:.4f}\")\n",
    "\n",
    "    # Predict and save sample outputs\n",
    "    predict_and_save_samples(model, x_test, y_test)\n",
    "```\n",
    "**Breakdown:**\n",
    "*   **Load Data:** Calls `load_and_preprocess_data()`.\n",
    "*   **Build and Compile Model:** Calls `build_model()`. Then, `model.compile(...)` configures training with:\n",
    "    *   `optimizer=\"adam\"`: Adam optimizer.\n",
    "    *   `loss=\"categorical_crossentropy\"`: Loss function for one-hot encoded multi-class classification.\n",
    "    *   `metrics=[\"accuracy\"]`: Metric to monitor.\n",
    "    *   `model.summary()`: Prints model layers and parameters.\n",
    "*   **Prepare TensorBoard Log Directory:** Creates a timestamped directory for logs.\n",
    "*   **Generate Visualkeras Architecture:** Uses `visualkeras.layered_view()` to create and save a diagram of the model.\n",
    "*   **Log Visualkeras Image to TensorBoard:** Reads the saved diagram and logs it to TensorBoard using `tf.summary.image`.\n",
    "*   **TensorBoard Callback:** `tf.keras.callbacks.TensorBoard(...)` logs metrics, graphs, histograms, etc., during training.\n",
    "*   **Train Model:** `model.fit(...)` starts training with specified batch size, epochs, validation split, and callbacks.\n",
    "*   **Evaluate:** `model.evaluate(...)` calculates loss and accuracy on the unseen test set.\n",
    "*   **Predict and Save:** Calls `predict_and_save_samples()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d87317",
   "metadata": {},
   "source": [
    "### `if __name__ == \"__main__\":`\n",
    "Ensures `main()` runs only when the script is executed directly.\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97610fb6",
   "metadata": {},
   "source": [
    "## 4. Setup and Running the Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0361121",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "*   Python 3 (e.g., 3.8+)\n",
    "*   `pip` (Python package installer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab1f09",
   "metadata": {},
   "source": [
    "### Installation Steps\n",
    "1.  **Clone the repository (if applicable):**\n",
    "    ```bash\n",
    "    # git clone <your-repo-url>\n",
    "    # cd Keras/FuncApiExample  (Adjust path as needed for your project structure)\n",
    "    ```\n",
    "2.  **Create a Python virtual environment:** (Highly recommended)\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    ```\n",
    "3.  **Activate the virtual environment:**\n",
    "    *   Linux/macOS:\n",
    "        ```bash\n",
    "        source venv/bin/activate\n",
    "        ```\n",
    "    *   Windows (PowerShell):\n",
    "        ```bash\n",
    "        .\\venv\\Scripts\\Activate.ps1\n",
    "        ```\n",
    "4.  **Install the required packages:** Ensure you have a `requirements.txt` file similar to this (based on the script's imports):\n",
    "    ```txt\n",
    "    tensorflow\n",
    "    numpy\n",
    "    matplotlib\n",
    "    visualkeras\n",
    "    ```\n",
    "    Then run:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "5.  **Install Graphviz (for Visualkeras to save complex model graphs, especially if not just using `to_file` with simple formats):**\n",
    "    Visualkeras might require Graphviz for some functionalities or for saving in formats like PDF or SVG directly. For PNG as used in the script, it might not be strictly necessary if its internal rendering is sufficient, but it's good practice to have it installed for full Keras/TensorFlow visualization capabilities.\n",
    "    *   **Debian/Ubuntu Linux:**\n",
    "        ```bash\n",
    "        sudo apt-get update\n",
    "        sudo apt-get install graphviz\n",
    "        ```\n",
    "    *   For other systems, refer to Graphviz installation guides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c022af0",
   "metadata": {},
   "source": [
    "### Running the Project\n",
    "Once setup is complete, run the main script (assuming it's named `main.py`):\n",
    "```bash\n",
    "python main.py\n",
    "```\n",
    "This will:\n",
    "- Load and preprocess the MNIST dataset.\n",
    "- Build the Keras Functional API model.\n",
    "- Train the model.\n",
    "- Evaluate the model on the test set.\n",
    "- Predict on a few random samples and save the images with their true and predicted labels in a `predictions` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef1b1e3",
   "metadata": {},
   "source": [
    "### Starting TensorBoard\n",
    "To view the logs (metrics, graph, model visualization):\n",
    "```bash\n",
    "tensorboard --logdir logs\n",
    "```\n",
    "Then open the provided URL (usually `http://localhost:6006`) in your web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be61e6",
   "metadata": {},
   "source": [
    "### Deactivating the Virtual Environment\n",
    "When finished:\n",
    "```bash\n",
    "deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ac6e9",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "This notebook has walked through a Python script for MNIST image classification using Keras and TensorFlow. We've covered data loading, preprocessing, model building (MLP), compilation, training, visualization with TensorBoard and Visualkeras, evaluation, and prediction.\n",
    "This script provides a solid foundation for understanding image classification with MLPs. From here, you can experiment with different network architectures, layers, neurons, optimizers, or try it on different datasets!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
